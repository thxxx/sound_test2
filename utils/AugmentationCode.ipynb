{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9acb54-b7e8-4ad7-8bf9-480a1cd512d9",
   "metadata": {},
   "source": [
    "### If"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 7,
   "id": "e9c84719-8128-4d50-b18d-f8a876971b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76675927daa4ba18a835dc8bae14b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "best.pth:   0%|          | 0.00/7.36G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'weight/best.pth'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "hf_hub_download(repo_id=\"youngdicey/audiogen-medium-pretraining-gdc\", filename=\"best.pth\", local_dir=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> f254427 (first commit)
   "execution_count": null,
   "id": "26d46ea6-44fe-4a34-942c-79390492bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 각기 다른 csv에 저장되어 있다면 우선 하나로 합치기\n",
    "import pandas as pd\n",
    "\n",
    "total_csv_path = \"\"\n",
    "\n",
    "csvs_to_combine = [\n",
    "    \"artlist_audios.csv\",\n",
    "    \"boom_ui_sounds.csv\",\n",
    "    \"epidemic_audios.csv\",\n",
    "    \"outsourced_sfx_data.csv\",\n",
    "    \"roblox_audios.csv\",\n",
    "    \"zapsplat_audios.csv\"\n",
    "]\n",
    "\n",
    "# Combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(\"./data_folder/\"+f) for f in csvs_to_combine])\n",
    "\n",
    "# Export to csv\n",
    "combined_csv.to_csv(total_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 27,
>>>>>>> f254427 (first commit)
   "id": "adc46187-21f7-463d-be38-7a0ccf4fba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 데이터가 하나의 csv 파일 안에 들어있다고 가정\n",
    "# attr은 audio_path, caption, duration\n",
    "# 우선 eval은 그대로 두기 위해서 train과 eval로 분리\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
<<<<<<< HEAD
    "total_csv_path = \"\"\n",
    "\n",
    "df = pd.read_csv(total_csv_path)\n",
    "df_sample_90 = df.sample(frac=0.9)\n",
    "df_sample_90.to_csv('train_total_mixed_csv.csv', index=False)\n",
    "df_sample_10 = df.drop(df_sample_90.index)\n",
    "df_sample_10.to_csv('eval_total_mixed_csv.csv', index=False)"
=======
    "total_csv_path = \"total_0201_processed.csv\"\n",
    "\n",
    "df = pd.read_csv(total_csv_path)\n",
    "df_sample_95 = df.sample(frac=0.95)\n",
    "df_sample_95.to_csv('train_0201.csv', index=False)\n",
    "df_sample_5 = df.drop(df_sample_95.index)\n",
    "df_sample_5.to_csv('eval_0201.csv', index=False)"
>>>>>>> f254427 (first commit)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e8e69d-adda-4a27-bb0a-ecaf97816415",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 24,
   "id": "55170b7a-08e3-44bd-a4ba-4ecada327c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 텍스트 전처리 내용\n",
    "# 1. 뒤에 문장이 부자연스럽게 끊기는건 제거, 2. 중복 문장 제거\n",
    "def pre_process_description(text):\n",
    "    text = text.strip()\n",
    "    \n",
    "    text = re.sub(\"Blastwave FX \", \"\", text)\n",
    "    text = re.sub(\"\\.WAV\", \"\", text)\n",
    "    text = re.sub(\"yourfreesounds\\.com\", \"\", text)\n",
    "    text = re.sub(\"BW\\.\", \"\", text)\n",
    "    text = re.sub(\"HV\\.\", \"\", text)\n",
    "    \n",
    "    caps = text.split(\".\")\n",
    "    if len(caps) == 1:\n",
    "        return text\n",
    "    \n",
    "    if len(caps) != len(set(caps)):\n",
    "        new_caps = []\n",
    "        for c in caps:\n",
    "            if c not in new_caps:\n",
    "                new_caps.append(c)\n",
    "        caps = new_caps\n",
    "    processed_text = \".\".join(caps[:-1])\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
>>>>>>> f254427 (first commit)
   "id": "16c3fa08-80e0-4ebd-8875-09ecfb2c20af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/tmp/ipykernel_4437/659662912.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "100%|██████████| 323581/323581 [00:17<00:00, 18220.19it/s]"
=======
      "100%|██████████| 323581/323581 [00:22<00:00, 14312.65it/s]"
>>>>>>> f254427 (first commit)
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 길이 :  323581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train만 읽어서 augment 하기\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import random\n",
    "\n",
<<<<<<< HEAD
    "total_train_data = pd.read_csv(\"/workspace/sound_test/csv_files/total_dataset_with_zapsplat_caption.csv\")\n",
    "\n",
    "datas = []\n",
=======
    "total_train_data = pd.read_csv(\"/workspace/sound_test/total_dataset_with_zapsplat_caption.csv\")\n",
    "\n",
    "datas = []\n",
    "rows = [['audio_path', 'caption', 'duration']]\n",
>>>>>>> f254427 (first commit)
    "for i in tqdm(range(len(total_train_data))):\n",
    "    row = total_train_data.iloc[i]\n",
    "    datas.append({\n",
    "        \"audio_path\":row['audio_path'],\n",
<<<<<<< HEAD
    "        \"caption\":row['caption'],\n",
    "        \"duration\":row['duration']\n",
    "    })\n",
=======
    "        \"caption\":pre_process_description(row['caption']),\n",
    "        \"duration\":row['duration']\n",
    "    })\n",
    "    rows.append([row['audio_path'], pre_process_description(row['caption']), row['duration']])\n",
>>>>>>> f254427 (first commit)
    "print(\"데이터 길이 : \", len(datas))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "id": "adeb26d7-101e-4229-ba48-408e14a90cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리 내용\n",
    "# 1. 뒤에 문장이 부자연스럽게 끊기는건 제거, 2. 중복 문장 제거\n",
    "def pre_process_description(text):\n",
    "    text = text.strip()\n",
    "    caps = text.split(\".\")\n",
    "    if len(caps) == 1:\n",
    "        return text\n",
    "    if len(caps) != len(set(caps)):\n",
    "        new_caps = []\n",
    "        for c in caps:\n",
    "            if c not in new_caps:\n",
    "                new_caps.append(c)\n",
    "        caps = new_caps\n",
    "    processed_text = \".\".join(caps[:-1])\n",
    "    return processed_text"
=======
   "execution_count": 26,
   "id": "b43ac15c-db04-4c6d-9fff-c46bf0645886",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"total_0201_processed.csv\", 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225fcbfa-86c7-42ad-84c1-d911d124a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_80/3976037327.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "100%|██████████| 307402/307402 [00:13<00:00, 22162.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 길이 :  307402\n"
     ]
    }
   ],
   "source": [
    "# train만 읽어서 augment 하기\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import random\n",
    "\n",
    "total_train_data = pd.read_csv(\"/workspace/sound_test/train_0201.csv\")\n",
    "\n",
    "datas = []\n",
    "for i in tqdm(range(len(total_train_data))):\n",
    "    row = total_train_data.iloc[i]\n",
    "    datas.append({\n",
    "        \"audio_path\": row['audio_path'],\n",
    "        \"caption\": row['caption'], # 한번 더하면 안돼!\n",
    "        \"duration\": row['duration']\n",
    "    })\n",
    "print(\"데이터 길이 : \", len(datas))"
>>>>>>> f254427 (first commit)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0717d-757a-4887-b597-60a0bab05506",
   "metadata": {},
   "source": [
    "### To mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "225d8d0c-2b39-49fe-b00f-8e86252ae527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "전체 사운드 개수 :  323581\n",
      "3초 이하 사운드 개수 :  150726\n"
=======
      "전체 사운드 개수 :  307402\n",
      "3초 이하 사운드 개수 :  143213\n"
>>>>>>> f254427 (first commit)
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "150726it [00:00, 346628.64it/s]\n"
=======
      "143213it [00:00, 436134.48it/s]\n"
>>>>>>> f254427 (first commit)
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "어그멘트 된 수 :  37263\n"
=======
      "어그멘트 된 수 :  42588\n"
>>>>>>> f254427 (first commit)
     ]
    }
   ],
   "source": [
    "mixed_csv_path = \"mixed_under3s.csv\"\n",
    "\n",
    "under_3seconds = [d for d in datas if d['duration']<=3]\n",
    "\n",
    "print(\"전체 사운드 개수 : \", len(datas))\n",
    "print(\"3초 이하 사운드 개수 : \", len(under_3seconds))\n",
    "\n",
    "def mix_caption(cap1, cap2):\n",
    "    return cap1 + \", \" + cap2\n",
    "\n",
    "# 여기선 그냥 정보만 저장. 실제로 합쳐서 쓰는건 DataLoader 단에서\n",
    "rows = []\n",
    "for idx, data in tqdm(enumerate(under_3seconds)):\n",
    "    # 전체의 N%만 남기기\n",
<<<<<<< HEAD
    "    N=25\n",
=======
    "    N=30\n",
>>>>>>> f254427 (first commit)
    "    rand_value = random.randint(0,100)\n",
    "    if rand_value>=N:\n",
    "        continue\n",
    "    \n",
    "    random_idx = idx # 어떤거랑 합칠지 선택\n",
    "    while random_idx == idx:\n",
    "        random_idx = random.randint(0, len(under_3seconds)-1)\n",
    "\n",
    "    added_audio_path = under_3seconds[random_idx][\"audio_path\"]\n",
<<<<<<< HEAD
    "    added_caption = pre_process_description(under_3seconds[random_idx][\"caption\"])\n",
    "    mixed_caption = mix_caption(pre_process_description(data[\"caption\"]), added_caption)\n",
    "\n",
    "    row = [data[\"audio_path\"], data[\"caption\"], data[\"duration\"], added_audio_path, added_caption, mixed_caption]\n",
    "    rows.append(row)\n",
    "\n",
    "print('어그멘트 된 수 : ', len(rows))\n",
    "rows_for_save = [[\"audio_path\", \"caption\", \"duration\", \"added_audio_path\", \"added_caption\", \"mixed_caption\"]]+rows\n",
=======
    "    added_caption = under_3seconds[random_idx][\"caption\"]\n",
    "    mixed_caption = mix_caption(data[\"caption\"], added_caption)\n",
    "\n",
    "    row = [data[\"audio_path\"], data[\"caption\"], data[\"duration\"], added_audio_path, added_caption, mixed_caption, \"mix\"]\n",
    "    rows.append(row)\n",
    "\n",
    "print('어그멘트 된 수 : ', len(rows))\n",
    "rows_for_save = [[\"audio_path\", \"caption\", \"duration\", \"added_audio_path\", \"added_caption\", \"mixed_caption\", \"typed\"]]+rows\n",
>>>>>>> f254427 (first commit)
    "\n",
    "with open(mixed_csv_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows_for_save)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 30,
>>>>>>> f254427 (first commit)
   "id": "7eacc41c-173b-4728-a2a4-c299db7b77ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "총 길이 :  356020\n"
=======
      "총 길이 :  342696\n"
>>>>>>> f254427 (first commit)
     ]
    }
   ],
   "source": [
    "# 위에서 만든 augment data를 다시 원본에 합쳐서, 증강된 데이터세트 만들기\n",
    "csvs_to_combine = [\n",
<<<<<<< HEAD
    "    \"/workspace/sound_test/csv_files/train_dataset_with_zapsplat_with_caption.csv\",\n",
=======
    "    \"/workspace/sound_test/utils/train_0201.csv\",\n",
>>>>>>> f254427 (first commit)
    "    mixed_csv_path\n",
    "]\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in csvs_to_combine])\n",
    "print(\"총 길이 : \", len(combined_csv))\n",
<<<<<<< HEAD
    "combined_csv.to_csv(\"train_dataset_with_zapsplat_with_caption_mixed.csv\", index=False)"
=======
    "combined_csv.to_csv(\"train_0201_mixed.csv\", index=False)"
>>>>>>> f254427 (first commit)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a01090-ff1e-4994-86fb-1fa7cf28b421",
   "metadata": {},
   "source": [
    "### To concat"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 5,
>>>>>>> f254427 (first commit)
   "id": "96a2ec1d-f42d-459f-8e75-555b04e0eb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "전체 사운드 개수 :  323581\n",
      "1.5초 이하 사운드 개수 :  102483\n"
=======
      "전체 사운드 개수 :  307402\n",
      "1.5초 이하 사운드 개수 :  97356\n"
>>>>>>> f254427 (first commit)
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "102483it [00:00, 296326.20it/s]\n"
=======
      "97356it [00:00, 374474.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "증강된 데이터 수 :  38139\n"
>>>>>>> f254427 (first commit)
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "concated_csv_path = \"concat_under15s.csv\"\n",
    "\n",
    "under_15seconds = [d for d in datas if d['duration']<=1.5]\n",
    "\n",
    "print(\"전체 사운드 개수 : \", len(datas))\n",
    "print(\"1.5초 이하 사운드 개수 : \", len(under_15seconds))\n",
    "\n",
    "def mix_caption(cap1, cap2):\n",
    "    concat_cap = \"\"\n",
    "    rv = random.randint(0,2)\n",
    "    if rv == 0:\n",
    "        concat_cap = cap1+\" followed by \"+cap2\n",
    "    if rv == 1:\n",
    "        concat_cap = cap1+\", and then \"+cap2\n",
    "    if rv == 2:\n",
    "        concat_cap = cap2+\" after \"+cap1\n",
    "    return concat_cap\n",
    "\n",
    "# 여기선 그냥 정보만 저장. 실제로 합쳐서 쓰는건 DataLoader 단에서\n",
    "rows = []\n",
    "for idx, data in tqdm(enumerate(under_15seconds)):\n",
    "    # 전체의 N%만 남기기\n",
<<<<<<< HEAD
    "    N=25\n",
    "    rand_value = random.randint(0,100)\n",
    "    if rand_value>=N:\n",
    "        if rand_value<35:\n",
    "            row = [data[\"audio_path\"], data[\"caption\"], data[\"duration\"], data[\"audio_path\"], data[\"caption\"], data[\"caption\"]+\", twice\"]\n",
=======
    "    N=30\n",
    "    rand_value = random.randint(0,100)\n",
    "    if rand_value>=N:\n",
    "        if rand_value<40:\n",
    "            row = [data[\"audio_path\"], data[\"caption\"], data[\"duration\"], data[\"audio_path\"], data[\"caption\"], data[\"caption\"]+\", twice\", \"concat\"]\n",
>>>>>>> f254427 (first commit)
    "            rows.append(row)\n",
    "        continue\n",
    "    \n",
    "    random_idx = idx # 어떤거랑 합칠지 선택\n",
    "    while random_idx == idx:\n",
    "        random_idx = random.randint(0, len(under_15seconds)-1)\n",
    "\n",
    "    added_audio_path = under_15seconds[random_idx][\"audio_path\"]\n",
<<<<<<< HEAD
    "    added_caption = pre_process_description(under_15seconds[random_idx][\"caption\"])\n",
    "    mixed_caption = mix_caption(pre_process_description(data[\"caption\"]), added_caption)\n",
    "\n",
    "    row = [data[\"audio_path\"], data[\"caption\"], data[\"duration\"], added_audio_path, added_caption, mixed_caption]\n",
    "    rows.append(row)\n",
    "\n",
    "rows_for_save = [[\"audio_path\", \"caption\", \"duration\", \"added_audio_path\", \"added_caption\", \"mixed_caption\"]]+rows\n",
=======
    "    added_caption = under_15seconds[random_idx][\"caption\"]\n",
    "    mixed_caption = mix_caption(data[\"caption\"], added_caption)\n",
    "\n",
    "    row = [data[\"audio_path\"], data[\"caption\"], data[\"duration\"], added_audio_path, added_caption, mixed_caption, \"concat\"]\n",
    "    rows.append(row)\n",
    "\n",
    "print(\"증강된 데이터 수 : \", len(rows))\n",
    "rows_for_save = [[\"audio_path\", \"caption\", \"duration\", \"added_audio_path\", \"added_caption\", \"mixed_caption\", \"typed\"]]+rows\n",
>>>>>>> f254427 (first commit)
    "\n",
    "with open(concated_csv_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows_for_save)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 6,
>>>>>>> f254427 (first commit)
   "id": "c53516f2-3ed1-455e-bb41-3f63d71ff8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 만든 augment data를 다시 원본에 합쳐서, 증강된 데이터세트 만들기\n",
    "csvs_to_combine = [\n",
<<<<<<< HEAD
    "    \"/workspace/sound_test/csv_files/train_dataset_with_zapsplat_with_caption.csv\",\n",
    "    concated_csv_path\n",
    "]\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in csvs_to_combine])\n",
    "combined_csv.to_csv(\"train_dataset_with_zapsplat_with_caption_concated.csv\", index=False)"
=======
    "    \"/workspace/sound_test/train_0201.csv\",\n",
    "    concated_csv_path,\n",
    "    mixed_csv_path\n",
    "]\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in csvs_to_combine])\n",
    "combined_csv.to_csv(\"train_0201_total.csv\", index=False)"
>>>>>>> f254427 (first commit)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422761db-d798-45eb-ad28-03e623701b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c17ef-7718-42b1-930d-09ed67d30cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
